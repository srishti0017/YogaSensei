{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a998c73f",
   "metadata": {},
   "source": [
    "# Dividing Video into 4 parts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b22af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Replace 'your_video.mp4' with the path to your video file\n",
    "video_path = r'd:\\Capstone\\Yoga Capstone\\videos1\\correct\\1.mp4'\n",
    "\n",
    "# Open the video file\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Get the frames per second (fps) and total frame count\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# Calculate the frame count for each segment\n",
    "frames_per_segment = total_frames // 4\n",
    "\n",
    "for i in range(4):\n",
    "    # Calculate the start and end frames for the segment\n",
    "    start_frame = i * frames_per_segment\n",
    "    end_frame = (i + 1) * frames_per_segment if i < 3 else total_frames\n",
    "    \n",
    "    # Set the output file name\n",
    "    output_file = f'C:/Users/Lenovo/Desktop/segment{i + 1}.mp4'\n",
    "    \n",
    "    # Initialize video writer\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_file, fourcc, fps, (int(cap.get(3)), int(cap.get(4))))\n",
    "    \n",
    "    # Read and write frames for the segment\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "    while cap.isOpened() and cap.get(cv2.CAP_PROP_POS_FRAMES) < end_frame:\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            out.write(frame)\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    # Release the video writer for this segment\n",
    "    out.release()\n",
    "\n",
    "# Release the video capture object\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61646edb",
   "metadata": {},
   "source": [
    "## Multi-Threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2654cdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import threading\n",
    "\n",
    "# Define your video processing function\n",
    "def process_video(video_path, window_name, results):\n",
    "    IMG_WIDTH, IMG_HEIGHT = 224, 224\n",
    "    \n",
    "    # Load the saved model\n",
    "    model = tf.keras.models.load_model(r'd:\\Capstone\\koi bhi\\Top_5_Models\\pose_classification_model_mobilenetv2.h5')\n",
    "\n",
    "    # Function to preprocess the frame for prediction\n",
    "    def preprocess_frame(frame, img_width, img_height):\n",
    "        resized_frame = cv2.resize(frame, (img_width, img_height))\n",
    "        preprocessed_frame = np.expand_dims(resized_frame, axis=0)\n",
    "        preprocessed_frame = preprocessed_frame / 255.0\n",
    "        return preprocessed_frame\n",
    "\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Variables to keep track of correct, partially correct, and incorrect frames\n",
    "    total_frames = 0\n",
    "    correct_frames = 0\n",
    "    partially_correct_frames = 0\n",
    "    incorrect_frames = 0\n",
    "    none_frames = 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Preprocess the frame for prediction\n",
    "        preprocessed_frame = preprocess_frame(frame, IMG_WIDTH, IMG_HEIGHT)\n",
    "\n",
    "        # Make predictions on the frame\n",
    "        predictions = model.predict(preprocessed_frame)\n",
    "        predicted_class = np.argmax(predictions, axis=1)\n",
    "\n",
    "        # Update counters based on the predicted class\n",
    "        total_frames += 1\n",
    "        if predicted_class[0] == 0:  # Correct class index\n",
    "            correct_frames += 1\n",
    "        elif predicted_class[0] == 3:  # Partially Correct class index\n",
    "            partially_correct_frames += 1\n",
    "        elif predicted_class[0] == 1:  # Incorrect class index\n",
    "            incorrect_frames += 1\n",
    "        elif predicted_class[0] == 2:  # None class index\n",
    "            none_frames += 1\n",
    "\n",
    "        # Get the class label as a string\n",
    "        class_labels = [\"Correct\", \"Incorrect\", \"None\", \"Partially Correct\"]\n",
    "        predicted_class_label = class_labels[predicted_class[0]]\n",
    "\n",
    "        # Display the predicted class on the frame\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        font_scale = 1\n",
    "        font_thickness = 2\n",
    "        text_size = cv2.getTextSize(predicted_class_label, font, font_scale, font_thickness)[0]\n",
    "        text_position = (10, 30)\n",
    "        text_background_position = (10, 10)\n",
    "        text_background_end_position = (10 + text_size[0] + 10, 10 + text_size[1] + 10)\n",
    "        cv2.rectangle(frame, text_background_position, text_background_end_position, (0, 0, 255), cv2.FILLED)\n",
    "        cv2.putText(frame, predicted_class_label, text_position, font, font_scale, (255, 255, 255), font_thickness)\n",
    "\n",
    "        # Display the frame in a separate window\n",
    "        cv2.imshow(window_name, frame)\n",
    "\n",
    "        # Exit the loop when 'q' key is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Calculate the scores\n",
    "    step = 100 / total_frames\n",
    "    score1 = step * correct_frames\n",
    "    score2 = step / 2 * partially_correct_frames\n",
    "    total_score = score1 + score2\n",
    "\n",
    "    # Store the statistics in the results dictionary\n",
    "    results[window_name] = {\n",
    "        \"Total Frames\": total_frames,\n",
    "        \"Correct Frames\": correct_frames,\n",
    "        \"Partially Correct Frames\": partially_correct_frames,\n",
    "        \"Incorrect Frames\": incorrect_frames,\n",
    "        \"None Frames\": none_frames,\n",
    "        \"Total Score\": total_score\n",
    "    }\n",
    "\n",
    "    # Release the video capture and close the display window\n",
    "    cap.release()\n",
    "    cv2.destroyWindow(window_name)\n",
    "\n",
    "# List of video file paths and corresponding window names\n",
    "video_files = [\n",
    "    (r'c:\\Users\\Lenovo\\Desktop\\segment1.mp4', \"Video 1\"),\n",
    "    (r'c:\\Users\\Lenovo\\Desktop\\segment2.mp4', \"Video 2\"),\n",
    "    (r'c:\\Users\\Lenovo\\Desktop\\segment3.mp4', \"Video 3\"),\n",
    "    (r'c:\\Users\\Lenovo\\Desktop\\segment4.mp4', \"Video 4\")\n",
    "]\n",
    "\n",
    "# Create a dictionary to store the results for each video\n",
    "results = {}\n",
    "\n",
    "# Create a thread for each video processing task\n",
    "threads = []\n",
    "\n",
    "for video_path, window_name in video_files:\n",
    "    thread = threading.Thread(target=process_video, args=(video_path, window_name, results))\n",
    "    threads.append(thread)\n",
    "    thread.start()\n",
    "\n",
    "# Wait for all threads to complete\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "# Calculate and display the overall scores\n",
    "overall_total_frames = sum(stats[\"Total Frames\"] for stats in results.values())\n",
    "overall_correct_frames = sum(stats[\"Correct Frames\"] for stats in results.values())\n",
    "overall_partially_correct_frames = sum(stats[\"Partially Correct Frames\"] for stats in results.values())\n",
    "overall_incorrect_frames = sum(stats[\"Incorrect Frames\"] for stats in results.values())\n",
    "overall_none_frames = sum(stats[\"None Frames\"] for stats in results.values())\n",
    "\n",
    "step = 100 / overall_total_frames\n",
    "overall_score1 = step * overall_correct_frames\n",
    "overall_score2 = step / 2 * overall_partially_correct_frames\n",
    "overall_total_score = overall_score1 + overall_score2\n",
    "\n",
    "print(\"Overall Scores:\")\n",
    "print(f\"Total Frames: {overall_total_frames}\")\n",
    "print(f\"Correct Frames: {overall_correct_frames}\")\n",
    "print(f\"Partially Correct Frames: {overall_partially_correct_frames}\")\n",
    "print(f\"Incorrect Frames: {overall_incorrect_frames}\")\n",
    "print(f\"None Frames: {overall_none_frames}\")\n",
    "print(f\"Total Score: {overall_total_score:.2f}\")\n",
    "\n",
    "# print(\"Individual Video Scores:\")\n",
    "# for video_name, video_stats in results.items():\n",
    "#     print(f\"{video_name}:\")\n",
    "#     for stat_name, stat_value in video_stats.items():\n",
    "#         print(f\"{stat_name}: {stat_value:.2f}\")\n",
    "\n",
    "print(\"All videos processed.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
