{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5368c963",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-25 03:27:11.003556: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-25 03:27:11.131058: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-25 03:27:11.131751: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-25 03:27:11.838839: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24855 images belonging to 4 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-25 03:27:12.859196: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-25 03:27:12.935160: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5636 images belonging to 4 classes.\n",
      "Epoch 1/25\n",
      "776/776 [==============================] - 377s 485ms/step - loss: 0.6801 - accuracy: 0.7081 - val_loss: 0.5012 - val_accuracy: 0.7718 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "776/776 [==============================] - 377s 486ms/step - loss: 0.3655 - accuracy: 0.8370 - val_loss: 0.2649 - val_accuracy: 0.9096 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "776/776 [==============================] - 374s 482ms/step - loss: 0.2966 - accuracy: 0.8700 - val_loss: 0.2471 - val_accuracy: 0.8951 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "776/776 [==============================] - 373s 481ms/step - loss: 0.2347 - accuracy: 0.9010 - val_loss: 0.1811 - val_accuracy: 0.9359 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "776/776 [==============================] - 373s 480ms/step - loss: 0.2024 - accuracy: 0.9167 - val_loss: 0.4245 - val_accuracy: 0.8482 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "776/776 [==============================] - 372s 479ms/step - loss: 0.1840 - accuracy: 0.9233 - val_loss: 0.1697 - val_accuracy: 0.9308 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "776/776 [==============================] - 372s 480ms/step - loss: 0.1587 - accuracy: 0.9366 - val_loss: 0.1697 - val_accuracy: 0.9292 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "776/776 [==============================] - 372s 479ms/step - loss: 0.1414 - accuracy: 0.9440 - val_loss: 0.2283 - val_accuracy: 0.9295 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "776/776 [==============================] - 374s 482ms/step - loss: 0.1387 - accuracy: 0.9478 - val_loss: 0.1041 - val_accuracy: 0.9632 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "776/776 [==============================] - 373s 481ms/step - loss: 0.1288 - accuracy: 0.9498 - val_loss: 0.2821 - val_accuracy: 0.9112 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "776/776 [==============================] - 377s 486ms/step - loss: 0.1166 - accuracy: 0.9552 - val_loss: 0.0506 - val_accuracy: 0.9830 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "776/776 [==============================] - 373s 481ms/step - loss: 0.1098 - accuracy: 0.9585 - val_loss: 0.1096 - val_accuracy: 0.9659 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "776/776 [==============================] - 374s 482ms/step - loss: 0.1025 - accuracy: 0.9607 - val_loss: 0.1213 - val_accuracy: 0.9581 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "776/776 [==============================] - 374s 481ms/step - loss: 0.0902 - accuracy: 0.9663 - val_loss: 0.0483 - val_accuracy: 0.9812 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "776/776 [==============================] - 372s 480ms/step - loss: 0.0963 - accuracy: 0.9654 - val_loss: 0.1337 - val_accuracy: 0.9483 - lr: 0.0010\n",
      "Epoch 16/25\n",
      "776/776 [==============================] - 375s 482ms/step - loss: 0.0864 - accuracy: 0.9676 - val_loss: 0.3090 - val_accuracy: 0.9196 - lr: 0.0010\n",
      "Epoch 17/25\n",
      "776/776 [==============================] - 375s 483ms/step - loss: 0.0885 - accuracy: 0.9677 - val_loss: 0.0641 - val_accuracy: 0.9790 - lr: 0.0010\n",
      "Epoch 18/25\n",
      "776/776 [==============================] - 373s 480ms/step - loss: 0.0510 - accuracy: 0.9799 - val_loss: 0.1028 - val_accuracy: 0.9682 - lr: 2.0000e-04\n",
      "Epoch 19/25\n",
      "776/776 [==============================] - 374s 482ms/step - loss: 0.0499 - accuracy: 0.9814 - val_loss: 0.0883 - val_accuracy: 0.9759 - lr: 2.0000e-04\n",
      "Epoch 20/25\n",
      "776/776 [==============================] - 376s 484ms/step - loss: 0.0488 - accuracy: 0.9819 - val_loss: 0.0565 - val_accuracy: 0.9817 - lr: 2.0000e-04\n",
      "Epoch 21/25\n",
      "776/776 [==============================] - 376s 484ms/step - loss: 0.0417 - accuracy: 0.9853 - val_loss: 0.0869 - val_accuracy: 0.9734 - lr: 4.0000e-05\n",
      "Epoch 22/25\n",
      "776/776 [==============================] - 375s 484ms/step - loss: 0.0404 - accuracy: 0.9844 - val_loss: 0.0818 - val_accuracy: 0.9751 - lr: 4.0000e-05\n",
      "Epoch 23/25\n",
      "776/776 [==============================] - 375s 482ms/step - loss: 0.0402 - accuracy: 0.9856 - val_loss: 0.0716 - val_accuracy: 0.9792 - lr: 4.0000e-05\n",
      "Epoch 24/25\n",
      "776/776 [==============================] - 375s 482ms/step - loss: 0.0403 - accuracy: 0.9851 - val_loss: 0.0772 - val_accuracy: 0.9771 - lr: 8.0000e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adarsh/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Define constants\n",
    "NUM_CLASSES = 4  # Number of classes (correct, partially correct, incorrect, none)\n",
    "IMG_WIDTH, IMG_HEIGHT = 224, 224  # Input image dimensions\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 25\n",
    "\n",
    "# Define the CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_WIDTH, IMG_HEIGHT, 3)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),  # Adjusted dropout rate\n",
    "    Dense(NUM_CLASSES, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Create data generators for training and validation with data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    '/home/adarsh/Desktop/yoga/train/',\n",
    "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    '/home/adarsh/Desktop/yoga/test/',\n",
    "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Define early stopping and learning rate schedule\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "lr_schedule = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)\n",
    "\n",
    "# Train the model with early stopping and learning rate schedule\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.n // BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.n // BATCH_SIZE,\n",
    "    callbacks=[early_stop, lr_schedule]  # Add early stopping and LR schedule to the callbacks\n",
    ")\n",
    "\n",
    "# Save the model for later use\n",
    "model.save('pose_classification_model_cnn.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
