{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33730cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-23 22:12:22.749154: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-23 22:12:22.771119: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-23 22:12:22.771607: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-23 22:12:23.284914: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-09-23 22:12:24.009652: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-23 22:12:24.030025: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24855 images belonging to 4 classes.\n",
      "Found 5636 images belonging to 4 classes.\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-23 22:12:25.977093: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 411041792 exceeds 10% of free system memory.\n",
      "2023-09-23 22:12:26.012051: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 411041792 exceeds 10% of free system memory.\n",
      "2023-09-23 22:12:29.163562: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 411041792 exceeds 10% of free system memory.\n",
      "2023-09-23 22:12:29.418980: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 411041792 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/776 [..............................] - ETA: 1:13:37 - loss: 8.4894 - accuracy: 0.0938"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-23 22:12:30.400664: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 411041792 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "776/776 [==============================] - 3454s 4s/step - loss: 1.7084 - accuracy: 0.3828 - val_loss: 1.3009 - val_accuracy: 0.4055 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "776/776 [==============================] - 3447s 4s/step - loss: 1.2496 - accuracy: 0.3981 - val_loss: 1.2260 - val_accuracy: 0.4050 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "776/776 [==============================] - 3815s 5s/step - loss: 1.1949 - accuracy: 0.3987 - val_loss: 1.1868 - val_accuracy: 0.4054 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "776/776 [==============================] - 6512s 8s/step - loss: 1.1699 - accuracy: 0.3992 - val_loss: 1.1696 - val_accuracy: 0.4055 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "776/776 [==============================] - 6541s 8s/step - loss: 1.1582 - accuracy: 0.3990 - val_loss: 1.1654 - val_accuracy: 0.4055 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "776/776 [==============================] - 6556s 8s/step - loss: 1.1531 - accuracy: 0.3989 - val_loss: 1.1593 - val_accuracy: 0.4057 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "776/776 [==============================] - 6473s 8s/step - loss: 1.1499 - accuracy: 0.3993 - val_loss: 1.1588 - val_accuracy: 0.4054 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "776/776 [==============================] - 6517s 8s/step - loss: 1.1495 - accuracy: 0.3990 - val_loss: 1.1571 - val_accuracy: 0.4052 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "776/776 [==============================] - 6497s 8s/step - loss: 1.1488 - accuracy: 0.3991 - val_loss: 1.1559 - val_accuracy: 0.4055 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "776/776 [==============================] - 6530s 8s/step - loss: 1.1492 - accuracy: 0.3988 - val_loss: 1.1570 - val_accuracy: 0.4055 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "776/776 [==============================] - 6323s 8s/step - loss: 1.1498 - accuracy: 0.3987 - val_loss: 1.1564 - val_accuracy: 0.4055 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "776/776 [==============================] - 6358s 8s/step - loss: 1.1499 - accuracy: 0.3990 - val_loss: 1.1578 - val_accuracy: 0.4054 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "776/776 [==============================] - 6384s 8s/step - loss: 1.1488 - accuracy: 0.3991 - val_loss: 1.1565 - val_accuracy: 0.4052 - lr: 2.0000e-04\n",
      "Epoch 14/25\n",
      "776/776 [==============================] - 6434s 8s/step - loss: 1.1485 - accuracy: 0.3991 - val_loss: 1.1566 - val_accuracy: 0.4057 - lr: 2.0000e-04\n",
      "Epoch 15/25\n",
      "776/776 [==============================] - 6397s 8s/step - loss: 1.1485 - accuracy: 0.3991 - val_loss: 1.1568 - val_accuracy: 0.4052 - lr: 2.0000e-04\n",
      "Epoch 16/25\n",
      "776/776 [==============================] - 6307s 8s/step - loss: 1.1484 - accuracy: 0.3990 - val_loss: 1.1565 - val_accuracy: 0.4054 - lr: 4.0000e-05\n",
      "Epoch 17/25\n",
      "776/776 [==============================] - 3364s 4s/step - loss: 1.1475 - accuracy: 0.3992 - val_loss: 1.1563 - val_accuracy: 0.4055 - lr: 4.0000e-05\n",
      "Epoch 18/25\n",
      "776/776 [==============================] - 3411s 4s/step - loss: 1.1481 - accuracy: 0.3990 - val_loss: 1.1565 - val_accuracy: 0.4054 - lr: 4.0000e-05\n",
      "Epoch 19/25\n",
      "776/776 [==============================] - 3434s 4s/step - loss: 1.1485 - accuracy: 0.3991 - val_loss: 1.1564 - val_accuracy: 0.4055 - lr: 8.0000e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adarsh/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "# Define constants\n",
    "NUM_CLASSES = 4  # Number of classes (correct, partially correct, incorrect, none)\n",
    "IMG_WIDTH, IMG_HEIGHT = 224, 224  # Input image dimensions for VGG16\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 25\n",
    "\n",
    "# Load VGG16 pre-trained model (include_top=False to exclude the classification layers)\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(IMG_WIDTH, IMG_HEIGHT, 3))\n",
    "\n",
    "# Flatten the output from the base model\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "x = Dense(1024, activation='relu', kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "x = Dropout(0.5)(x)  # Adjusted dropout rate\n",
    "predictions = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Implement a learning rate schedule\n",
    "lr_schedule = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Create data generators for training and validation with data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    '/home/adarsh/Desktop/yoga/train/',\n",
    "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    '/home/adarsh/Desktop/yoga/test/',\n",
    "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Define early stopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model with early stopping and learning rate schedule\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.n // BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.n // BATCH_SIZE,\n",
    "    callbacks=[early_stop, lr_schedule]  # Add early stopping and LR schedule to the callbacks\n",
    ")\n",
    "\n",
    "# Save the model for later use\n",
    "model.save('pose_classification_model_vgg16.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
